{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "# import requests\n",
    "from collections import Counter\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from xml.dom.minidom import parse, parseString\n",
    "from lxml import etree\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "\n",
    "\n",
    "import re\n",
    "# import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# alignment\n",
    "from IlCodiCE import add_variant, alignment\n",
    "\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_folder_first = \"entrez_api_downloads/first_api/\"\n",
    "# local_folder_second = \"entrez_api_downloads/second_api/\"\n",
    "\n",
    "dowload_folder = \"downloads/\"\n",
    "local_folder = dowload_folder + \"entrez_api/\"\n",
    "local_folder_taxonomy = dowload_folder + \"entrez_api_taxonomy/\"\n",
    "local_folder_variant = dowload_folder + \"variant/\"\n",
    "local_folder_sequence = dowload_folder +\"sequence/\"\n",
    "\n",
    "\n",
    "\n",
    "for folder in [local_folder, local_folder_taxonomy, local_folder_variant, local_folder_sequence]:# [local_folder_first, local_folder_second]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# entrez package setting\n",
    "Entrez.email = \"Your.Name.Here@example.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import ExperimentType, SequencingProject, Virus, HostSample, Sequence, Annotation, Variant\n",
    "from database import base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine  \n",
    "\n",
    "# connect to db\n",
    "db_string = \"postgresql://geco:geco78@localhost:5432/vcm_dev\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "# create session\n",
    "Session = sessionmaker(db)  \n",
    "session = Session()\n",
    "\n",
    "# TODO REMOVE\n",
    "base.metadata.drop_all(db)\n",
    "base.metadata.create_all(db)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error printing helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(e):\n",
    "    res = etree.tostring(e, encoding=\"unicode\", pretty_print=True)\n",
    "    print(res)\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_text(el, path, mandatory = True):\n",
    "    res = el.xpath(path)\n",
    "    assert len(res) == 1 if mandatory else len(res) <= 1, f\"{path} is available {len(res)} time(s)\"\n",
    "    \n",
    "    if res:\n",
    "        return res[0].text\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_id = 2697049\n",
    "\n",
    "def get_taxonomy_tree(taxid):\n",
    "    local_file_path = f\"{local_folder_taxonomy}/{taxid}.xml\"\n",
    "    if not os.path.exists(local_file_path):\n",
    "        with Entrez.efetch(db=\"taxonomy\", id=taxid,rettype=None,retmode=\"xml\") as handle \\\n",
    "             , open(local_file_path,'w')as f: \n",
    "            for line in handle:\n",
    "                f.write(line)\n",
    "    tree = etree.parse(local_file_path, parser = etree.XMLParser(remove_blank_text=True))\n",
    "    return tree\n",
    "# tax_tree = get_taxonomy_tree(taxonomy_id)\n",
    "# pretty(tax_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronaviridae Orthocoronavirinae Betacoronavirus Severe acute respiratory syndrome-related coronavirus SARS-CoV2 SARS-CoV2, 2019-nCoV, COVID-19, COVID-19 virus, COVID19, HCoV-19, Human coronavirus 2019, SARS-2, SARS-CoV-2, SARS2, Wuhan coronavirus, Wuhan seafood market pneumonia virus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add_virus(taxonomy_id):\n",
    "    tax_tree = get_taxonomy_tree(taxonomy_id)\n",
    "    assert str(taxonomy_id) == path_text(tax_tree, './Taxon/TaxId')\n",
    "    scientific_name = path_text(tax_tree, './Taxon/ScientificName')\n",
    "    \n",
    "    family = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"family\"]/ScientificName')\n",
    "    subfamily = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"subfamily\"]/ScientificName')\n",
    "    genus = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"genus\"]/ScientificName')\n",
    "    species = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"species\"]/ScientificName')\n",
    "#     species_taxon_id = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"species\"]/TaxId')\n",
    "    \n",
    "    genbank_acronym = path_text(tax_tree, './/GenbankAcronym')\n",
    "    equivalent_names = tax_tree.xpath('.//EquivalentName')\n",
    "    equivalent_names = [x.text for x in equivalent_names]\n",
    "    if genbank_acronym:\n",
    "        equivalent_names.insert(0, genbank_acronym)\n",
    "    equivalent_names = list(OrderedDict.fromkeys(equivalent_names))\n",
    "    equivalent_names = \", \".join(equivalent_names)\n",
    "\n",
    "\n",
    "    \n",
    "    print(family, subfamily, genus, species, genbank_acronym, equivalent_names)\n",
    "    \n",
    "\n",
    "    molecule_type= 'RNA'\n",
    "    is_single_stranded = True\n",
    "    is_positive_stranded = True\n",
    "\n",
    "    \n",
    "    virus = session.query(Virus).filter(Virus.taxon_id == taxonomy_id).one_or_none()\n",
    "    \n",
    "    if not virus:\n",
    "#         print(\"not exists\")\n",
    "        virus = Virus(taxon_id = taxonomy_id,\n",
    "                      taxon_name = scientific_name,\n",
    "                      \n",
    "                      family=family,\n",
    "                      sub_family=subfamily,\n",
    "                      genus=genus,\n",
    "                      species=species,\n",
    "                      equivalent_list=equivalent_names,\n",
    "                      molecule_type=molecule_type,\n",
    "                      is_single_stranded=is_single_stranded,\n",
    "                      is_positive_stranded=is_positive_stranded\n",
    "                     )\n",
    "        session.add(virus)\n",
    "        session.commit()\n",
    "    \n",
    "#     print(experiment.experiment_type_id)\n",
    "    return virus\n",
    "virus = add_virus(taxonomy_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1798174254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retmax = 100000\n",
    "\n",
    "handle = Entrez.esearch(db=\"nuccore\", term=f\"(txid{taxonomy_id}[Organism]) AND srcdb_refseq[Properties]\", retmax=retmax)\n",
    "accession_ids = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "# print(accession_ids)\n",
    "assert int(accession_ids['Count']) <= retmax, \"retmax is not enough\" + \"please check: https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\"\n",
    "\n",
    "accession_ids = accession_ids['IdList']\n",
    "reference_accession_id = [int(x) for x in accession_ids]\n",
    "len(set(accession_ids))\n",
    "assert len(set(accession_ids)) == 1, f\"Multiple references of txid{taxonomy_id}\"\n",
    "reference_accession_id = reference_accession_id[0]\n",
    "\n",
    "reference_accession_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle = Entrez.esearch(db=\"nuccore\", term=\"txid2697049[Organism:noexp]\", retmax=10000)\n",
    "# Entrez.esearch(db=\"nuccore\", term=\"txid2697049\", retmax=10000, retmode='json', idtype='acc')\n",
    "# could be json and idtype acc\n",
    "handle = Entrez.esearch(db=\"nuccore\", term=f\"(txid{taxonomy_id}[Organism])\", retmax=retmax)\n",
    "accession_ids = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "# print(accession_ids)\n",
    "assert int(accession_ids['Count']) <= retmax, \"retmax is not enough\" + \"please check: https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\"\n",
    "\n",
    "\n",
    "accession_ids = accession_ids['IdList']\n",
    "accession_ids = [int(x) for x in accession_ids]\n",
    "len(set(accession_ids))\n",
    "accession_ids.remove(reference_accession_id)\n",
    "len(set(accession_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# returns first one if exists\n",
    "def coalesce(input_list, result_type='', mandatory = True, multiple=False): \n",
    "    res = [x for x in input_list if x!=None]\n",
    "    \n",
    "    if mandatory:\n",
    "        assert len(set(res)) >= 1, f\"{result_type} is not available: len: {len(set(res))}, input: {input_list}\"\n",
    "        \n",
    "    if not multiple:\n",
    "        assert len(set(res)) <= 1, f\"# of elements for {result_type} must be one. len: {len(set(res))}, input: {input_list}\"\n",
    "        \n",
    "    \n",
    "    if res:\n",
    "        return res[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def structured_comment(el, key):\n",
    "    comment = path_text(el, './/INSDSeq_comment' , False)\n",
    "    if comment:   \n",
    "        sub = re.findall(\"##Assembly-Data-START## ;(.*); ##Assembly-Data-END##\", comment)\n",
    "        assert len(sub) <=1, f\"multiple structured_comment {len(sub)}\"\n",
    "        if sub:\n",
    "            sub = sub[0]\n",
    "            subs = sub.split(\";\")\n",
    "            subs = [x for x in subs if key in x]\n",
    "            assert len(subs) <=1, f\"multiple structured_comment for key: {key} {len(subs)}\"\n",
    "            if subs:\n",
    "                return subs[0].split(\"::\")[1].strip()\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def complete(tree):\n",
    "    definition = path_text(tree, \".//INSDSeq_definition\")\n",
    "    definition_0 = definition.split(\";\")[0]\n",
    "    definition_0_last = definition_0.split(\",\")[-1]\n",
    "    definition_0_last = definition_0_last.strip()\n",
    "    if definition_0_last in ['complete genome', ]:\n",
    "        return True\n",
    "    elif definition_0_last in ['partial cds', 'complete cds', 'partial genome']:\n",
    "        return False\n",
    "    else:\n",
    "        accession_id = path_text(tree, './/INSDSeq_accession-version')\n",
    "        eprint(f\"In {accession_id}, unkown complete string: {definition_0_last}\" )\n",
    "        return None\n",
    "    \n",
    "# CHECK\n",
    "# https://www.ncbi.nlm.nih.gov/nuccore/MT345845 there are 4 intervals in mat_peptide\n",
    "def merge_intervals(e):\n",
    "    intervals = e.xpath(\".//INSDInterval\")\n",
    "    intervals2 = []\n",
    "    for i in intervals:\n",
    "        start = int(path_text(i, './/INSDInterval_from'))\n",
    "        stop = int(path_text(i, './/INSDInterval_to'))\n",
    "        intervals2.append((start,stop))\n",
    "    \n",
    "    if intervals:\n",
    "        \n",
    "        min_start = min(x[0] for x in intervals2)\n",
    "        max_stop = max(x[1] for x in intervals2)\n",
    "        return min_start, max_stop  \n",
    "    else:\n",
    "        None\n",
    "    return len(intervals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(e, sequence_id):\n",
    "    start, stop = merge_intervals(e)\n",
    "    feature_type = path_text(e, './/INSDFeature_key')\n",
    "    gene_name = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"gene\"]/INSDQualifier_value' , False)   \n",
    "\n",
    "    product = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"product\"]/INSDQualifier_value' , False) \n",
    "    db_xref = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"db_xref\"]/INSDQualifier_value' , False) \n",
    "\n",
    "    protein_id = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"protein_id\"]/INSDQualifier_value' , False) \n",
    "\n",
    "    if protein_id:\n",
    "        protein_id = \"ProteinID:\" + protein_id\n",
    "\n",
    "    # merge with comma\n",
    "    db_xref_merged = [x for x in [protein_id, db_xref] if x != None]\n",
    "\n",
    "    db_xref_merged = ','.join(db_xref_merged)\n",
    "    #  select one of them:\n",
    "#         db_xref_merged = coalesce(db_xref_merged,'db_xref', mandatory=False, multiple=True)\n",
    "\n",
    "\n",
    "    res = (start, stop, feature_type, gene_name, product, db_xref_merged)\n",
    "#         print(res)\n",
    "    if feature_type != 'source':\n",
    "        annotation = Annotation(feature_type=feature_type,\n",
    "                  start=start,\n",
    "                  stop=stop,\n",
    "                  gene_name=gene_name,\n",
    "                  product=product,\n",
    "                  external_reference=db_xref_merged,\n",
    "                  sequence_id=sequence_id)\n",
    "        session.add(annotation)\n",
    "        session.commit()\n",
    "        return res\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_annotations(tree, sequence_id):\n",
    "    annotations =[]\n",
    "    for e in tree.xpath(\".//INSDFeature\"):\n",
    "        try:\n",
    "            res = get_annotation(e, sequence_id)\n",
    "        except AssertionError:\n",
    "            pass\n",
    "        else:\n",
    "            if res:\n",
    "                annotations.append(res)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variant(sequence_id, start, variant_length, sequence_original,  alternative_sequence, variant_type):\n",
    "    variant = Variant(sequence_id=sequence_id,\n",
    "                      start_original=int(start), \n",
    "                      start_alternative=None,\n",
    "                      sequence_original = sequence_original,\n",
    "                      sequence_alternative=alternative_sequence,\n",
    "                      variant_length=variant_length,\n",
    "                      variant_type=variant_type)\n",
    "\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "# session.query(SequencingProject).delete()\n",
    "\n",
    "def get_experiment(tree):\n",
    "    assembly_method = structured_comment(tree,'Assembly Method')\n",
    "    sequencing_technology = structured_comment(tree,'Sequencing Technology')\n",
    "    coverage = structured_comment(tree,'Coverage')\n",
    "    \n",
    "    experiment = session.query(ExperimentType).filter(ExperimentType.sequencing_technology == sequencing_technology, \n",
    "                                              ExperimentType.assembly_method == assembly_method,\n",
    "                                              ExperimentType.coverage == coverage).one_or_none()\n",
    "    \n",
    "    if not experiment:\n",
    "#         print(\"not exists\")\n",
    "        experiment = ExperimentType(sequencing_technology=sequencing_technology, assembly_method=assembly_method,coverage=coverage)\n",
    "        session.add(experiment)\n",
    "        session.commit()\n",
    "    \n",
    "#     print(experiment.experiment_type_id)\n",
    "    return experiment\n",
    "    \n",
    "\n",
    "def get_sequencing_project(tree):\n",
    "    references = tree.xpath('.//INSDReference[./INSDReference_title/text() = \"Direct Submission\"]')\n",
    "\n",
    "    assert len(references) > 0, 'there must be at least one direct submission'\n",
    "    reference = references[0]\n",
    "#     authors = reference.xpath('.//INSDAuthor')\n",
    "#     authors = [x.text for x in authors]\n",
    "#     authors = \", \".join(authors)\n",
    "#     title = path_text(reference, \"./INSDReference_title\")\n",
    "#     journal = path_text(reference, \"./INSDReference_journal\")\n",
    "#     publication_date = None\n",
    "#     pubmed_id = path_text(reference, \"./INSDReference_pubmed\" , mandatory=False)\n",
    "#     popset = None\n",
    "\n",
    "    journal = path_text(reference, \"./INSDReference_journal\")\n",
    "#     print(journal)\n",
    "#     assert journal.startswith(\"Submitted \"), 'Cannot find submitted in the Journal of direct submission reference'\n",
    "    journal_split = re.split(\"[()]\", journal, maxsplit=2)\n",
    "    assert len(journal_split) == 3, f\"Journal value problem '{journal}' {journal_split}\"\n",
    "    submitted, submission_date, sequencing_lab = journal_split\n",
    "    assert submitted == \"Submitted \", \"Journal value submitted\"\n",
    "    submission_date = datetime.strptime(submission_date, '%d-%b-%Y')\n",
    "    \n",
    "    \n",
    "    \n",
    "    keyword = path_text(tree, \".//INSDKeyword\", mandatory=False)\n",
    "    is_reference = keyword == \"RefSeq\"\n",
    "    \n",
    "    bioproject_id = path_text(tree, './/INSDXref[./INSDXref_dbname/text() = \"BioProject\"]/INSDXref_id', mandatory=False)\n",
    "    database_source = \"RefSeq\" if is_reference else \"GenBank\"\n",
    "    \n",
    "\n",
    "    sequencing_project = session.query(SequencingProject).filter(SequencingProject.sequencing_lab == sequencing_lab,\n",
    "                                              SequencingProject.submission_date == submission_date,\n",
    "                                              SequencingProject.bioproject_id == bioproject_id,\n",
    "                                              SequencingProject.database_source == database_source\n",
    "                                        ).one_or_none()\n",
    "    \n",
    "    if not sequencing_project:\n",
    "#         print(\"not exists\")\n",
    "        sequencing_project = SequencingProject(sequencing_lab = sequencing_lab,\n",
    "                                              submission_date = submission_date,\n",
    "                                              bioproject_id = bioproject_id,\n",
    "                                              database_source = database_source)\n",
    "        session.add(sequencing_project)\n",
    "        session.commit()\n",
    "    return sequencing_project\n",
    "\n",
    "\n",
    "def get_host_sample(tree):\n",
    "    references = tree.xpath('.//INSDReference[./INSDReference_title/text() = \"Direct Submission\"]')\n",
    "    assert len(references) > 0, 'there must be at least one direct submission'\n",
    "    reference = references[0]\n",
    "    journal = path_text(reference, \"./INSDReference_journal\")\n",
    "    journal_split = re.split(\"[()]\", journal, maxsplit=2)\n",
    "    assert len(journal_split) == 3, f\"Journal value problem '{journal}' {journal_split}\"\n",
    "    submitted, submission_date, originating_lab = journal_split\n",
    "\n",
    "    originating_lab = None\n",
    "    \n",
    "    host = path_text(tree, '..//INSDQualifier[./INSDQualifier_name/text() = \"host\"]/INSDQualifier_value', mandatory=False)\n",
    "    host = [x.strip() for x in host.split(\";\")] if host else []\n",
    "    \n",
    "    host_taxon_name = host[0] if len(host) else None\n",
    "    \n",
    "    host = [x.lower() for x in host]\n",
    "    gender = 'male' if 'male' in host else 'female' if 'female' in host else None\n",
    "    age = next(filter(lambda x:'age' in x, host), None)\n",
    "    if age:\n",
    "        age = int(age.replace(\"age\", '').strip())\n",
    "        \n",
    "\n",
    "    \n",
    "    host_taxon_id = 9606 if host_taxon_name == 'Homo sapiens' else None\n",
    "    \n",
    "    collection_date = path_text(tree, '..//INSDQualifier[./INSDQualifier_name/text() = \"collection_date\"]/INSDQualifier_value', mandatory=False)\n",
    "    isolation_source = path_text(tree, '..//INSDQualifier[./INSDQualifier_name/text() = \"isolation_source\"]/INSDQualifier_value', mandatory=False)\n",
    "\n",
    "    country = None\n",
    "    region = None\n",
    "    geo_group = None   \n",
    "    \n",
    "    country_pre = path_text(tree, '..//INSDQualifier[./INSDQualifier_name/text() = \"country\"]/INSDQualifier_value', mandatory=False )\n",
    "    if country_pre:\n",
    "        country_pre = country_pre.split(\":\")\n",
    "        country = country_pre[0]\n",
    "        region = country_pre[1] if len(country_pre) > 1 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    host_sample = session.query(HostSample).filter(HostSample.host_taxon_id == host_taxon_id,\n",
    "                                                   HostSample.host_taxon_name == host_taxon_name,\n",
    "                                                   \n",
    "                                                   HostSample.collection_date == collection_date,\n",
    "                                                   HostSample.isolation_source == isolation_source,\n",
    "                                                   \n",
    "                                                   HostSample.originating_lab == originating_lab,\n",
    "                                                   HostSample.country == country,\n",
    "                                                   HostSample.region == region,\n",
    "                                                   HostSample.geo_group == geo_group,\n",
    "                                                   HostSample.age == age,\n",
    "                                                   HostSample.gender == gender,\n",
    "                                                  ).one_or_none()\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "    if not host_sample:\n",
    "#         print(\"not exists\")\n",
    "        host_sample = HostSample(host_taxon_id = host_taxon_id,\n",
    "                                 host_taxon_name = host_taxon_name,\n",
    "                                                   \n",
    "                                 collection_date = collection_date,\n",
    "                                 isolation_source = isolation_source,\n",
    "                                 \n",
    "                                 originating_lab = originating_lab,\n",
    "                                 country = country,\n",
    "                                 region = region,\n",
    "                                 geo_group = geo_group,\n",
    "                                 age = age,\n",
    "                                 gender = gender,\n",
    "                                )\n",
    "    \n",
    "        session.add(host_sample)\n",
    "        session.commit()\n",
    "    return host_sample\n",
    "\n",
    "# tree = get_tree(reference_accession_id)\n",
    "# tree = get_tree(acc_id)\n",
    "# get_sequencing_project(tree)\n",
    "# get_host_sample(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = None\n",
    "def check(tree, alternative_accession_id):\n",
    "    global variants\n",
    "\n",
    "\n",
    "    \n",
    "    experiment = get_experiment(tree)\n",
    "    sequencing_project = get_sequencing_project(tree)\n",
    "    host_sample = get_host_sample(tree)\n",
    "\n",
    "\n",
    "    has_nucleotide_sequence = path_text(tree, './/INSDSeq_sequence',False)\n",
    "    if has_nucleotide_sequence:\n",
    "    \n",
    "        accession_id = path_text(tree, './/INSDSeq_accession-version')\n",
    "        strain = path_text(tree, './/INSDQualifier[./INSDQualifier_name/text() = \"strain\"]/INSDQualifier_value' , False)\n",
    "        isolate = path_text(tree, './/INSDQualifier[./INSDQualifier_name/text() = \"isolate\"]/INSDQualifier_value' , False)\n",
    "        strain_isolate = coalesce([strain, isolate],mandatory = False, multiple=True)\n",
    "\n",
    "        # <INSDKeyword>RefSeq</INSDKeyword> ??\n",
    "#         is_reference = accession_id.startswith(\"NC_\")\n",
    "        keyword = path_text(tree, \".//INSDKeyword\", mandatory=False)\n",
    "        is_reference = keyword == \"RefSeq\"\n",
    "\n",
    "        is_complete = complete(tree)\n",
    "        nucleotide_sequence = path_text(tree, './/INSDSeq_sequence')\n",
    "        strand = 'positive'\n",
    "        length = int(path_text(tree, './/INSDSeq_length'))\n",
    "        assert length == len(nucleotide_sequence)\n",
    "\n",
    "        c = Counter(nucleotide_sequence.lower())\n",
    "        gc_percentage = (c['g'] + c['c']) / (c['g'] + c['c'] + c['a'] + c['t'] + c['u']) * 100\n",
    "        gc_percentage = Decimal(gc_percentage)\n",
    "        gc_percentage = round(gc_percentage,2)\n",
    "        \n",
    "\n",
    "\n",
    "        sequence = Sequence(accession_id=accession_id,\n",
    "                 alternative_accession_id=alternative_accession_id,\n",
    "                 strain_name=strain_isolate,\n",
    "                 is_reference=is_reference,\n",
    "                 is_complete=is_complete,\n",
    "                 nucleotide_sequence=nucleotide_sequence,\n",
    "                 strand=strand,\n",
    "                 length=length,\n",
    "                 gc_percentage=gc_percentage,\n",
    "                 experiment_type_id=experiment.experiment_type_id,\n",
    "                 sequencing_project_id=sequencing_project.sequencing_project_id,\n",
    "                 virus_id = virus.virus_id,\n",
    "                 host_sample_id = host_sample.host_sample_id)\n",
    "        \n",
    "        session.add(sequence)\n",
    "        session.commit()\n",
    "        \n",
    "        if sequence_saving: \n",
    "            sequence_file = f\"{local_folder_sequence}/{alternative_accession_id}_{accession_id}_sequence.txt\"\n",
    "            if not os.path.exists(sequence_file):\n",
    "                with open(sequence_file, \"w\") as f:\n",
    "                    f.write(nucleotide_sequence)\n",
    "        \n",
    "        get_annotations(tree, sequence.sequence_id)\n",
    "        \n",
    "#         ALIGNMENT\n",
    "        if reference_sequence and variant_calling:\n",
    "            variant_file = f\"{local_folder_variant}/{reference_accession_id}_to_{alternative_accession_id}.csv\"\n",
    "            if os.path.exists(variant_file):\n",
    "                variants_df = pd.read_csv(variant_file)\n",
    "                variants = [add_variant(sequence.sequence_id, *x) for x in variants_df.values]\n",
    "            else:\n",
    "                variants = alignment(sequence.sequence_id, reference_sequence, nucleotide_sequence, add_variant=add_variant)\n",
    "                variants_df = [x.get_list() for x in variants]\n",
    "                variants_df = pd.DataFrame(variants_df, columns=Variant.get_list_columns())\n",
    "                variants_df.to_csv(variant_file, index=None)\n",
    "                \n",
    "            for variant in variants:\n",
    "                session.add(variant)\n",
    "                session.commit()\n",
    "        \n",
    "        return nucleotide_sequence\n",
    "\n",
    "        \n",
    "#         return coverage\n",
    "\n",
    "#         return (accession_id, strain_isolate, is_reference, is_complete, nucleotide_sequence[:10], strand, length, gc_percentage,) + \\\n",
    "#         (assembly_method, sequencing_technology, coverage)\n",
    "\n",
    "\n",
    "#     return max((merge_intervals(e) for e in tree.xpath(\".//INSDFeature\")))\n",
    "        \n",
    "# check(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a56a46797442cea21524cc6ac42c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3498.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In LR757995.1, unkown complete string: chromosome: whole_genome\n",
      "In LR757996.1, unkown complete string: chromosome: whole_genome\n",
      "In LR757997.1, unkown complete string: chromosome: whole_genome\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-32b8e89b2d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# for count, acc_id in enumerate([1798174254]): #refseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtree_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_and_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-32b8e89b2d45>\u001b[0m in \u001b[0;36mdownload_and_check\u001b[0;34m(acc_id)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_and_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-2051c3449acf>\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(tree, alternative_accession_id)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariants\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnucleotide_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0msa_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No transaction is begun.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPREPARED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_prepare_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 raise exc.FlushError(\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   2635\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m                 \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_capture_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m     def bulk_save_objects(\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 compat.raise_(\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 )\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   2595\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m                 \u001b[0mflush_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2598\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopological\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostsort_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_flush_changes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, uow)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0muow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_for_mapper_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0muow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36msave_obj\u001b[0;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0minsert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36m_emit_insert_statements\u001b[0;34m(base_mapper, uowtransaction, cached_connections, mapper, table, insert, bookkeeping)\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                     result = cached_connections[connection].execute(\n\u001b[0;32m-> 1136\u001b[0;31m                         \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                     )\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m    982\u001b[0m             )\n\u001b[1;32m    983\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1288\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 )\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1248\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m                     )\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vcm/lib/python3.7/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO DELETE\n",
    "session = Session()\n",
    "session.query(Variant).delete()\n",
    "session.query(Annotation).delete()\n",
    "session.query(Sequence).delete()\n",
    "session.query(ExperimentType).delete()\n",
    "session.query(SequencingProject).delete()\n",
    "\n",
    "\n",
    "variant_calling = True\n",
    "sequence_saving = False\n",
    "\n",
    "tree= None\n",
    "\n",
    "def get_tree(acc_id):\n",
    "    global tree\n",
    "    local_file_path = f\"{local_folder}/{acc_id}.xml\"\n",
    "    if not os.path.exists(local_file_path):\n",
    "        with Entrez.efetch(db=\"nuccore\", id=acc_id,rettype=\"gbc\",retmode=\"xml\") as handle \\\n",
    "             , open(local_file_path,'w')as f: \n",
    "            for line in handle:\n",
    "                f.write(line)\n",
    "    tree = etree.parse(local_file_path, parser = etree.XMLParser(remove_blank_text=True))\n",
    "    return tree\n",
    "\n",
    "def download_and_check(acc_id):\n",
    "    tree = get_tree(acc_id)\n",
    "    return check(tree, acc_id)\n",
    "\n",
    "\n",
    "reference_sequence = None\n",
    "reference_sequence = download_and_check(reference_accession_id)\n",
    "\n",
    "\n",
    "tree_results = []\n",
    "accession_ids_sub = accession_ids[::-1]\n",
    "# accession_ids_sub = accession_ids_sub[3178:3181]\n",
    "for count, acc_id in enumerate(tqdm(accession_ids_sub)):\n",
    "    pass\n",
    "# for count, acc_id in enumerate([\"1832307573\"]): #partial\n",
    "    pass\n",
    "# for count, acc_id in enumerate([1798174254]): #refseq\n",
    "\n",
    "    tree_results.append(download_and_check(acc_id))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ee4decdca3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook entrez_api.ipynb to script\n",
      "[NbConvertApp] Writing 24683 bytes to entrez_api.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script 'entrez_api.ipynb'\n",
    "!sed -i 's/vcm_dev/vcm_02/g' entrez_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tree.xpath(\".//INSDFeature\"):\n",
    "    INSDFeature_location = x.find('.//INSDFeature_location').text\n",
    "    try:\n",
    "        INSDInterval_from = x.find('.//INSDInterval_from').text\n",
    "    except:\n",
    "        INSDInterval_from = None\n",
    "    \n",
    "    try:\n",
    "        INSDInterval_to = x.find('.//INSDInterval_to').text\n",
    "    except:\n",
    "        INSDInterval_to = None\n",
    "    \n",
    "    \n",
    "    print(INSDFeature_location, \"&\", INSDInterval_from, \"&\", INSDInterval_to)\n",
    "\n",
    "#     pretty(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = get_tree(reference_accession_id)\n",
    "# # pretty(tree.find(\".//INSDSeq_references\"))\n",
    "# reference_accession_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = pd.read_csv(\"sequences.csv\")\n",
    "# csv.set_index(\"Accession\")\n",
    "# print(csv.shape)\n",
    "# # csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = get_tree(reference_accession_id)\n",
    "# # pretty(tree)\n",
    "# # path_text(tree,\".//INSDKeyword\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_len = []\n",
    "# ref_len2 = []\n",
    "# for count, acc_id in enumerate(tqdm(accession_ids)):\n",
    "#     tree = get_tree(acc_id)\n",
    "#     references = tree.xpath('.//INSDReference')\n",
    "#     ref_len.append(len(references))\n",
    "#     if len(references) == 2:\n",
    "#         ref_len2.append(acc_id)\n",
    "    \n",
    "# #     path_text(tree,\".//INSDKeyword\")\n",
    "# #     pretty(tree)\n",
    "# #     break\n",
    "# ref_len2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vcm",
   "language": "python",
   "name": "vcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
