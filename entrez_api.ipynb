{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "# import requests\n",
    "from collections import Counter\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from xml.dom.minidom import parse, parseString\n",
    "from lxml import etree\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "\n",
    "\n",
    "import re\n",
    "# import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# alignment\n",
    "from IlCodiCE import add_variant, alignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_folder_first = \"entrez_api_downloads/first_api/\"\n",
    "# local_folder_second = \"entrez_api_downloads/second_api/\"\n",
    "\n",
    "dowload_folder = \"downloads/\"\n",
    "local_folder = dowload_folder + \"entrez_api/\"\n",
    "local_folder_taxonomy = dowload_folder + \"entrez_api_taxonomy/\"\n",
    "local_folder_variant = dowload_folder + \"variant/\"\n",
    "local_folder_sequence = dowload_folder +\"sequence/\"\n",
    "\n",
    "\n",
    "\n",
    "for folder in [local_folder, local_folder_taxonomy, local_folder_variant, local_folder_sequence]:# [local_folder_first, local_folder_second]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# entrez package setting\n",
    "Entrez.email = \"Your.Name.Here@example.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import ExperimentType, SequenceProject, Virus, HostSample, Sequence, Annotation, Variant\n",
    "from database import base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine  \n",
    "\n",
    "# connect to db\n",
    "db_string = \"postgresql://geco:geco78@localhost:5432/vcm_dev\"\n",
    "db = create_engine(db_string)\n",
    "\n",
    "# create session\n",
    "Session = sessionmaker(db)  \n",
    "session = Session()\n",
    "\n",
    "# TODO REMOVE\n",
    "base.metadata.drop_all(db)\n",
    "base.metadata.create_all(db)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error printing helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(e):\n",
    "    res = etree.tostring(e, encoding=\"unicode\", pretty_print=True)\n",
    "    print(res)\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_id = 2697049\n",
    "\n",
    "def get_taxonomy_tree(taxid):\n",
    "    local_file_path = f\"{local_folder_taxonomy}/{taxid}.xml\"\n",
    "    if not os.path.exists(local_file_path):\n",
    "        with Entrez.efetch(db=\"taxonomy\", id=taxid,rettype=None,retmode=\"xml\") as handle \\\n",
    "             , open(local_file_path,'w')as f: \n",
    "            for line in handle:\n",
    "                f.write(line)\n",
    "    tree = etree.parse(local_file_path, parser = etree.XMLParser(remove_blank_text=True))\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_text(el, path, mandatory = True):\n",
    "    res = el.xpath(path)\n",
    "    assert len(res) == 1 if mandatory else len(res) <= 1, f\"{path} is available {len(res)} time(s)\"\n",
    "    \n",
    "    if res:\n",
    "        return res[0].text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def add_virus(taxonomy_id):\n",
    "    tax_tree = get_taxonomy_tree(taxonomy_id)\n",
    "    \n",
    "    family = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"family\"]/ScientificName')\n",
    "    subfamily = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"subfamily\"]/ScientificName')\n",
    "    genus = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"genus\"]/ScientificName')\n",
    "    species = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"species\"]/ScientificName')\n",
    "    species_taxon_id = path_text(tax_tree, './/LineageEx/Taxon[./Rank/text() = \"species\"]/TaxId')\n",
    "    genbank_acronym = path_text(tax_tree, './/GenbankAcronym')\n",
    "\n",
    "    equivalent_names = tax_tree.xpath('.//EquivalentName')\n",
    "    equivalent_names = [x.text for x in equivalent_names]\n",
    "    equivalent_names = \", \".join(equivalent_names)\n",
    "\n",
    "    print(family, subfamily, genus, species, species_taxon_id, genbank_acronym, equivalent_names)\n",
    "    \n",
    "#     virus_taxonomy_id = Column(Integer, primary_key=True, autoincrement=False)\n",
    "#     family = Column(String)\n",
    "#     sub_family = Column(String)\n",
    "#     genus  = Column(String)\n",
    "#     species_name = Column(String)\n",
    "#     species_taxon_id = Column(String)\n",
    "#     genbank_acronym = Column(String)\n",
    "#     equivalent_list = Column(String)\n",
    "#     molecule_type = Column(String)\n",
    "#     is_single_stranded = Column(String)\n",
    "#     is_positive_stranded = Column(String)\n",
    "\n",
    "    species_name= '??' + species\n",
    "    molecule_type= '??RNA'\n",
    "    is_single_stranded='TODO'\n",
    "    is_positive_stranded='TODO'\n",
    "\n",
    "    \n",
    "    virus = session.query(Virus).filter(Virus.virus_taxonomy_id == taxonomy_id).one_or_none()\n",
    "    \n",
    "    if not virus:\n",
    "#         print(\"not exists\")\n",
    "        virus = Virus(virus_taxonomy_id = taxonomy_id,\n",
    "                      family=family,\n",
    "                      sub_family=subfamily,\n",
    "                      genus=genus,\n",
    "                      species_name=species_name,\n",
    "                      species_taxon_id=species_taxon_id,\n",
    "                      genbank_acronym=genbank_acronym,\n",
    "                      equivalent_list=equivalent_names,\n",
    "                      molecule_type=molecule_type,\n",
    "                      is_single_stranded=is_single_stranded,\n",
    "                      is_positive_stranded=is_positive_stranded\n",
    "                     )\n",
    "        session.add(virus)\n",
    "        session.commit()\n",
    "    \n",
    "#     print(experiment.experiment_type_id)\n",
    "    return virus\n",
    "add_virus(taxonomy_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty(tax_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle = Entrez.esearch(db=\"nuccore\", term=\"txid2697049\", retmax=10000, retmode='json', idtype='acc')\n",
    "# print(handle.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retmax = 100000\n",
    "\n",
    "handle = Entrez.esearch(db=\"nuccore\", term=f\"(txid{taxonomy_id}[Organism]) AND srcdb_refseq[Properties]\", retmax=retmax)\n",
    "accession_ids = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "# print(accession_ids)\n",
    "assert int(accession_ids['Count']) <= retmax, \"retmax is not enough\" + \"please check: https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\"\n",
    "\n",
    "accession_ids = accession_ids['IdList']\n",
    "reference_accession_id = [int(x) for x in accession_ids]\n",
    "len(set(accession_ids))\n",
    "assert len(set(accession_ids)) == 1, f\"Multiple references of txid{taxonomy_id}\"\n",
    "reference_accession_id = reference_accession_id[0]\n",
    "\n",
    "reference_accession_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle = Entrez.esearch(db=\"nuccore\", term=\"txid2697049[Organism:noexp]\", retmax=10000)\n",
    "# Entrez.esearch(db=\"nuccore\", term=\"txid2697049\", retmax=10000, retmode='json', idtype='acc')\n",
    "# could be json and idtype acc\n",
    "handle = Entrez.esearch(db=\"nuccore\", term=f\"(txid{taxonomy_id}[Organism])\", retmax=retmax)\n",
    "accession_ids = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "# print(accession_ids)\n",
    "assert int(accession_ids['Count']) <= retmax, \"retmax is not enough\" + \"please check: https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\"\n",
    "\n",
    "\n",
    "accession_ids = accession_ids['IdList']\n",
    "accession_ids = [int(x) for x in accession_ids]\n",
    "len(set(accession_ids))\n",
    "accession_ids.remove(reference_accession_id)\n",
    "len(set(accession_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = pd.read_csv(\"sequences.csv\")\n",
    "# csv.set_index(\"Accession\")\n",
    "# print(csv.shape)\n",
    "# # csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Entrez.efetch(db=\"nuccore\", id=\"MN970004\",rettype=\"gbc\",retmode=\"xml\") as handle:\n",
    "#     tree = etree.parse(handle, parser = etree.XMLParser(remove_blank_text=True))\n",
    "# accession_id = path_text(tree, './/INSDSeq_accession-version')\n",
    "# accession_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# returns first one if exists\n",
    "def coalesce(input_list, result_type='', mandatory = True, multiple=False): \n",
    "    res = [x for x in input_list if x!=None]\n",
    "    \n",
    "    if mandatory:\n",
    "        assert len(set(res)) >= 1, f\"{result_type} is not available: len: {len(set(res))}, input: {input_list}\"\n",
    "        \n",
    "    if not multiple:\n",
    "        assert len(set(res)) <= 1, f\"# of elements for {result_type} must be one. len: {len(set(res))}, input: {input_list}\"\n",
    "        \n",
    "    \n",
    "    if res:\n",
    "        return res[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def structured_comment(el, key):\n",
    "    comment = path_text(el, './/INSDSeq_comment' , False)\n",
    "    if comment:   \n",
    "        sub = re.findall(\"##Assembly-Data-START## ;(.*); ##Assembly-Data-END##\", comment)\n",
    "        assert len(sub) <=1, f\"multiple structured_comment {len(sub)}\"\n",
    "        if sub:\n",
    "            sub = sub[0]\n",
    "            subs = sub.split(\";\")\n",
    "            subs = [x for x in subs if key in x]\n",
    "            assert len(subs) <=1, f\"multiple structured_comment for key: {key} {len(subs)}\"\n",
    "            if subs:\n",
    "                return subs[0].split(\"::\")[1].strip()\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def complete(tree):\n",
    "    definition = path_text(tree, \".//INSDSeq_definition\")\n",
    "    definition_0 = definition.split(\";\")[0]\n",
    "    definition_0_last = definition_0.split(\",\")[-1]\n",
    "    definition_0_last = definition_0_last.strip()\n",
    "    if definition_0_last in ['complete genome', ]:\n",
    "        return True\n",
    "    elif definition_0_last in ['partial cds', 'complete cds', 'partial genome']:\n",
    "        return False\n",
    "    else:\n",
    "        accession_id = path_text(tree, './/INSDSeq_accession-version')\n",
    "        eprint(f\"In {accession_id}, unkown complete string: {definition_0_last}\" )\n",
    "        return None\n",
    "    \n",
    "# CHECK\n",
    "# https://www.ncbi.nlm.nih.gov/nuccore/MT345845 there are 4 intervals in mat_peptide\n",
    "def merge_intervals(e):\n",
    "    intervals = e.xpath(\".//INSDInterval\")\n",
    "    intervals2 = []\n",
    "    for i in intervals:\n",
    "        start = int(path_text(i, './/INSDInterval_from'))\n",
    "        stop = int(path_text(i, './/INSDInterval_to'))\n",
    "        intervals2.append((start,stop))\n",
    "    \n",
    "    if intervals:\n",
    "        \n",
    "        min_start = min(x[0] for x in intervals2)\n",
    "        max_stop = max(x[1] for x in intervals2)\n",
    "        return min_start, max_stop  \n",
    "    else:\n",
    "        None\n",
    "    return len(intervals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(tree, sequence_id):\n",
    "    annotations =[]\n",
    "    for e in tree.xpath(\".//INSDFeature\"):\n",
    "        start, stop = merge_intervals(e)\n",
    "        feature_type = path_text(e, './/INSDFeature_key')\n",
    "        gene_name = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"gene\"]/INSDQualifier_value' , False)   \n",
    "\n",
    "        product = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"product\"]/INSDQualifier_value' , False) \n",
    "        db_xref = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"db_xref\"]/INSDQualifier_value' , False) \n",
    "\n",
    "        protein_id = path_text(e, './/INSDQualifier[./INSDQualifier_name/text() = \"protein_id\"]/INSDQualifier_value' , False) \n",
    "\n",
    "        if protein_id:\n",
    "            protein_id = \"ProteinID:\" + protein_id\n",
    "\n",
    "        # merge with comma\n",
    "        db_xref_merged = [x for x in [protein_id, db_xref] if x != None]\n",
    "        \n",
    "        db_xref_merged = ','.join(db_xref_merged)\n",
    "        #  select one of them:\n",
    "#         db_xref_merged = coalesce(db_xref_merged,'db_xref', mandatory=False, multiple=True)\n",
    "        \n",
    "        \n",
    "        res = (start, stop, feature_type, gene_name, product, db_xref_merged)\n",
    "#         print(res)\n",
    "        if feature_type != 'source':\n",
    "            annotation = Annotation(feature_type=feature_type,\n",
    "                      start=start,\n",
    "                      stop=stop,\n",
    "                      gene_name=gene_name,\n",
    "                      product=product,\n",
    "                      external_reference=db_xref_merged,\n",
    "                      sequence_id=sequence_id)\n",
    "            annotations.append(res)\n",
    "            session.add(annotation)\n",
    "            session.commit()\n",
    "            \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variant(sequence_id, start, length, original_sequence,  alt_sequence, variant_type):\n",
    "    variant = Variant(sequence_id=sequence_id,\n",
    "                      start=int(start),\n",
    "                      original_sequence = original_sequence,\n",
    "                      alt_sequence=alt_sequence,\n",
    "                      length=length,\n",
    "                      variant_type=variant_type)\n",
    "\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "# session.query(SequenceProject).delete()\n",
    "\n",
    "def get_experiment(tree):\n",
    "    assembly_method = structured_comment(tree,'Assembly Method')\n",
    "    sequencing_technology = structured_comment(tree,'Sequencing Technology')\n",
    "    coverage = structured_comment(tree,'Coverage')\n",
    "    \n",
    "    experiment = session.query(ExperimentType).filter(ExperimentType.sequencing_technology == sequencing_technology, \n",
    "                                              ExperimentType.assembly_method == assembly_method,\n",
    "                                              ExperimentType.coverage == coverage).one_or_none()\n",
    "    \n",
    "    if not experiment:\n",
    "#         print(\"not exists\")\n",
    "        experiment = ExperimentType(sequencing_technology=sequencing_technology, assembly_method=assembly_method,coverage=coverage)\n",
    "        session.add(experiment)\n",
    "        session.commit()\n",
    "    \n",
    "#     print(experiment.experiment_type_id)\n",
    "    return experiment\n",
    "    \n",
    "\n",
    "def get_sequencing_project(tree):\n",
    "    references = tree.xpath('.//INSDReference[./INSDReference_title/text() = \"Direct Submission\"]')\n",
    "\n",
    "    assert len(references) > 0, 'there must be at least one direct submission'\n",
    "    reference = references[0]\n",
    "#     authors = reference.xpath('.//INSDAuthor')\n",
    "#     authors = [x.text for x in authors]\n",
    "#     authors = \", \".join(authors)\n",
    "#     title = path_text(reference, \"./INSDReference_title\")\n",
    "#     journal = path_text(reference, \"./INSDReference_journal\")\n",
    "#     publication_date = None\n",
    "#     pubmed_id = path_text(reference, \"./INSDReference_pubmed\" , mandatory=False)\n",
    "#     popset = None\n",
    "\n",
    "    journal = path_text(reference, \"./INSDReference_journal\")\n",
    "#     print(journal)\n",
    "#     assert journal.startswith(\"Submitted \"), 'Cannot find submitted in the Journal of direct submission reference'\n",
    "    journal_split = re.split(\"[()]\", journal, maxsplit=2)\n",
    "    assert len(journal_split) == 3, f\"Journal value problem '{journal}' {journal_split}\"\n",
    "    submitted, submission_date, sequencing_lab = journal_split\n",
    "    assert submitted == \"Submitted \", \"Journal value submitted\"\n",
    "    submission_date = datetime.strptime(submission_date, '%d-%b-%Y')\n",
    "    \n",
    "    \n",
    "    \n",
    "    keyword = path_text(tree, \".//INSDKeyword\", mandatory=False)\n",
    "    is_reference = keyword == \"RefSeq\"\n",
    "    \n",
    "    bioproject_id = path_text(tree, './/INSDXref[./INSDXref_dbname/text() = \"BioProject\"]/INSDXref_id', mandatory=False)\n",
    "    database_source = \"RefSeq\" if is_reference else \"GenBank\"\n",
    "    \n",
    "\n",
    "    sequencing_project = session.query(SequenceProject).filter(SequenceProject.sequencing_lab == sequencing_lab,\n",
    "                                              SequenceProject.submission_date == submission_date,\n",
    "                                              SequenceProject.bioproject_id == bioproject_id,\n",
    "                                              SequenceProject.database_source == database_source\n",
    "                                        ).one_or_none()\n",
    "    \n",
    "    if not sequencing_project:\n",
    "#         print(\"not exists\")\n",
    "        sequencing_project = SequenceProject( sequencing_lab = sequencing_lab,\n",
    "                                              submission_date = submission_date,\n",
    "                                              bioproject_id = bioproject_id,\n",
    "                                              database_source = database_source)\n",
    "        session.add(sequencing_project)\n",
    "        session.commit()\n",
    "    return sequencing_project\n",
    "\n",
    "\n",
    "\n",
    "# tree = get_tree(reference_accession_id)\n",
    "# tree = get_tree(acc_id)\n",
    "# get_sequencing_project(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(tree, alternative_accession_id):\n",
    "    \n",
    "    experiment = get_experiment(tree)\n",
    "    sequencing_project = get_sequencing_project(tree)\n",
    "    \n",
    "    has_nucleotide_sequence = path_text(tree, './/INSDSeq_sequence',False)\n",
    "    if has_nucleotide_sequence:\n",
    "    \n",
    "        accession_id = path_text(tree, './/INSDSeq_accession-version')\n",
    "        strain = path_text(tree, './/INSDQualifier[./INSDQualifier_name/text() = \"strain\"]/INSDQualifier_value' , False)\n",
    "        isolate = path_text(tree, './/INSDQualifier[./INSDQualifier_name/text() = \"isolate\"]/INSDQualifier_value' , False)\n",
    "        strain_isolate = coalesce([strain, isolate],mandatory = False, multiple=True)\n",
    "\n",
    "        # <INSDKeyword>RefSeq</INSDKeyword> ??\n",
    "#         is_reference = accession_id.startswith(\"NC_\")\n",
    "        keyword = path_text(tree, \".//INSDKeyword\", mandatory=False)\n",
    "        is_reference = keyword == \"RefSeq\"\n",
    "\n",
    "        is_complete = complete(tree)\n",
    "        nucleotide_sequence = path_text(tree, './/INSDSeq_sequence')\n",
    "        strand = 'positive'\n",
    "        length = int(path_text(tree, './/INSDSeq_length'))\n",
    "        assert length == len(nucleotide_sequence)\n",
    "\n",
    "        c = Counter(nucleotide_sequence.lower())\n",
    "        gc_percentage = (c['g'] + c['c']) / (c['g'] + c['c'] + c['a'] + c['t'] + c['u']) * 100\n",
    "        gc_percentage = Decimal(gc_percentage)\n",
    "        gc_percentage = round(gc_percentage,2)\n",
    "\n",
    "\n",
    "        sequence = Sequence(accession_id=accession_id,\n",
    "                 alternative_accession_id=alternative_accession_id,\n",
    "                 strain_name=strain_isolate,\n",
    "                 is_reference=is_reference,\n",
    "                 is_complete=is_complete,\n",
    "                 nucleotide_sequence=nucleotide_sequence,\n",
    "                 strand=strand,\n",
    "                 length=length,\n",
    "                 gc_percentage=gc_percentage,\n",
    "                 experiment_type_id=experiment.experiment_type_id,\n",
    "                 sequence_project_id=sequencing_project.sequence_project_id)\n",
    "        \n",
    "        session.add(sequence)\n",
    "        session.commit()\n",
    "        \n",
    "        if sequence_saving: \n",
    "            sequence_file = f\"{local_folder_sequence}/{alternative_accession_id}_{accession_id}_sequence.txt\"\n",
    "            if not os.path.exists(sequence_file):\n",
    "                with open(sequence_file, \"w\") as f:\n",
    "                    f.write(nucleotide_sequence)\n",
    "        \n",
    "        get_annotations(tree, sequence.sequence_id)\n",
    "        \n",
    "#         ALIGNMENT\n",
    "        if reference_sequence and variant_calling:\n",
    "            variant_file = f\"{local_folder_variant}/{reference_accession_id}_to_{alternative_accession_id}.csv\"\n",
    "            if os.path.exists(variant_file):\n",
    "                variants_df = pd.read_csv(variant_file)\n",
    "                variants = [add_variant(sequence.sequence_id, *x) for x in variants_df.values]\n",
    "            else:\n",
    "                variants = alignment(sequence.sequence_id, reference_sequence, nucleotide_sequence)\n",
    "                variants_df = [x.get_list() for x in variants]\n",
    "                variants_df = pd.DataFrame(variants_df, columns=Variant.get_list_columns())\n",
    "                variants_df.to_csv(variant_file, index=None)\n",
    "                \n",
    "            for variant in variants:\n",
    "                session.add(variant)\n",
    "                session.commit()\n",
    "        \n",
    "        return nucleotide_sequence\n",
    "\n",
    "        \n",
    "#         return coverage\n",
    "\n",
    "#         return (accession_id, strain_isolate, is_reference, is_complete, nucleotide_sequence[:10], strand, length, gc_percentage,) + \\\n",
    "#         (assembly_method, sequencing_technology, coverage)\n",
    "\n",
    "\n",
    "#     return max((merge_intervals(e) for e in tree.xpath(\".//INSDFeature\")))\n",
    "        \n",
    "# check(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO DELETE\n",
    "session = Session()\n",
    "session.query(Variant).delete()\n",
    "session.query(Annotation).delete()\n",
    "session.query(Sequence).delete()\n",
    "session.query(ExperimentType).delete()\n",
    "session.query(SequenceProject).delete()\n",
    "\n",
    "\n",
    "variant_calling = True\n",
    "sequence_saving = False\n",
    "\n",
    "def get_tree(acc_id):\n",
    "    local_file_path = f\"{local_folder}/{acc_id}.xml\"\n",
    "    if not os.path.exists(local_file_path):\n",
    "        with Entrez.efetch(db=\"nuccore\", id=acc_id,rettype=\"gbc\",retmode=\"xml\") as handle \\\n",
    "             , open(local_file_path,'w')as f: \n",
    "            for line in handle:\n",
    "                f.write(line)\n",
    "    tree = etree.parse(local_file_path, parser = etree.XMLParser(remove_blank_text=True))\n",
    "    return tree\n",
    "\n",
    "def download_and_check(acc_id):\n",
    "    tree = get_tree(acc_id)\n",
    "    return check(tree, acc_id)\n",
    "\n",
    "\n",
    "reference_sequence = None\n",
    "reference_sequence = download_and_check(reference_accession_id)\n",
    "\n",
    "\n",
    "tree_results = []\n",
    "for count, acc_id in enumerate(tqdm(accession_ids[::-1])):\n",
    "    pass\n",
    "# for count, acc_id in enumerate([\"1832307573\"]): #partial\n",
    "    pass\n",
    "# for count, acc_id in enumerate([1798174254]): #refseq\n",
    "\n",
    "    tree_results.append(download_and_check(acc_id))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script 'entrez_api.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = get_tree(reference_accession_id)\n",
    "# # pretty(tree.find(\".//INSDSeq_references\"))\n",
    "# reference_accession_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = get_tree(reference_accession_id)\n",
    "# # pretty(tree)\n",
    "# # path_text(tree,\".//INSDKeyword\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_len = []\n",
    "# ref_len2 = []\n",
    "# for count, acc_id in enumerate(tqdm(accession_ids)):\n",
    "#     tree = get_tree(acc_id)\n",
    "#     references = tree.xpath('.//INSDReference')\n",
    "#     ref_len.append(len(references))\n",
    "#     if len(references) == 2:\n",
    "#         ref_len2.append(acc_id)\n",
    "    \n",
    "# #     path_text(tree,\".//INSDKeyword\")\n",
    "# #     pretty(tree)\n",
    "# #     break\n",
    "# ref_len2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vcm",
   "language": "python",
   "name": "vcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
